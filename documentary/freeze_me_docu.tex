\documentclass[12pt]{scrartcl}
\usepackage[german]{babel}
\usepackage{graphicx}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{color}
\usepackage[linkcolor=black, urlcolor=black, citecolor=dblue,
breaklinks, bookmarks, colorlinks]{hyperref}

\begin {document}

\hspace{-0.4cm}\huge \textbf{Freeze Me! - Dokumentation}\vspace{3pt}\\\Large A Media Processing Project \vspace{14pt}\large 

\noindent
\textbf{Stand:} Tag der Abgabe! \\ 

\vspace{3pt} \normalsize Gruppe: 
Jan Rekemeyer, Iskander Yusupov und Hendrik Finke

\section{Motivation}
Da das Ziel des Projekts darin bestand, ein Softwareprodukt zu erstellen, entschied sich die Gruppe, eine Motivation im Marketingformat zu erstellen.\\Gl\"uckliche Momente lassen sich in einem Foto festhalten, das dann verschenkt werden kann. Aber was tun mit den gl\"ucklichen Momenten, die auf Video festgehalten wurden? Mit diesem Ansatz suchte die Gruppe nach M\"oglichkeiten, ein Video so in Form eines Bildes festzuhalten, dass dieses sp\"ater beispielsweise als gerahmtes Geschenk pr\"asentiert werden k\"onnte.
Eine weitere Inspiration f\"ur unsere Gruppe waren Videos mit viel Dynamik. Sport, Tanz, aber auch Tiktok-Challenges enthalten viel Bewegung. Beim Fotografieren von sich bewegenden Objekten erzeugt die Einstellung einer Langzeitbeleuchtung den Effekt einer \glqq eingefrorenen\grqq  Bewegung. Diese Fotos haben ihre eigene \"Asthetik und unsere Gruppe wollte versuchen, diesen Effekt mit den im Modul erlernten F\"ahigkeiten zu reproduzieren.

\section{Zielsetzung}Unser Projekt haben wir der folgende Zielsetzung gewidmet: \\
\textit{Wir entwickeln ein Programm, welches es erm\"oglicht aus einem Video ein Bild zu erzeugen, welches die Bewegungsdynamik des Videos \"asthetisch einfasst und dabei den Eindruck fortw\"ahrender Bewegung erh\"alt.}

% Anforderungsanalyse

% Langzeitbelichtung
% -> Motivation, Theorie, Codebeschreibung, Resultate
% Grabcut mit Thresholding
% -> Motivation, Theorie, Codebeschreibung, Resultate
% Canny-Edge Detection
Motivation\\
Nachdem es der Gruppe gelungen war, Bilder mit einer k\"unstlichen Langzeitblichtung aus dem Video zu erstellen, fiel ein Merkmal auf. Wurde das Video ohne Stativ oder jegliche Art von Unterst\"utzung gedreht, dann führte das leichte Wackeln der Kamera irgendwann dazu, dass sich auch stabile Objekte im Ausgabebild als unscharf herausstellten. Um dieses Merkmal oder Problem zu l\"osen, wurde entschieden, Canny Edge Detection zu verwenden.
Die Idee, der Algorithmus zu verwenden, wurde experimentell geboren. Wir haben versucht, Canny Edge Detection auf ein bereits bearbeitetes Bild anzuwenden. Die Methode erkannte nur Objekte als Kanten, die auf dem Video stabil waren. Dann entschied die Gruppe, dass es m\"oglich ist, Sch\"arfungsverfahren (z. B. einen Laplace-Filter) auf die Pixelkoordinaten mit stabilen Objekten anzuwenden, die mithilfe des Canny Edge Detection auf dem Ausgabebild erhalten werden.
Theorie\\
Der Canny Edge Detection ist ein mehrstufiger Algorithmus zum Erkennen von Kanten in einem Bild. Der Algorithmus besteht aus vier Stufen. In der ersten Stufe ist es notwendig, Rauschen aus dem Originalbild zu entfernen, f\"ur diese Aufgabe wird der Gau{\ss} Filter angewendet. Der zweite Stufe besteht darin, den Gr\"o{\ss}e entlang der x- und y-Dimension zu erhalten. Dazu wird die Ableitung des Gau{\ss}-Filters berechnet, um dann das Gradient der Bildpixel zu berechnen.
Der Algorithmus geht alle Punkte der Gradientenintensit\"atsmatrix durch und findet die Pixel mit dem maximalen Wert in den Kantenrichtungen.
Das Betrachten der Gruppe von Nachbarn f\"ur jede Kurve in einer Richtung senkrecht zu der gegebenen Kante unterdr\"uckt nicht maximalen Kantenbeitragspixelpunkte. Schlie{\ss}lich wird das Hysterese-Schwellenwertverfahren verwendet, um die Pixel zu bewahren, die h\"oher als die Gradientengr\"o{\ss}e sind, und diejenigen zu vernachl\"assigen, die niedriger als der niedrige Schwellenwert sind.\\
Codebeschreibung.
Zur Optimierung der Ergebnisse wird ein Verfahren zur Bestimmung der Schwellwerte (minVal und maxVal) eingesetzt. Die Schwellwerte werden dann in der OpenCV Methode cv.Canny \"ubergegeben.\\
Ergebnis\\
Nach dem Ausf\"uhren des Codes ist das erwartete Ergebnis ein Bild mit identifizierten Kanten. Nach Auswertung der Ergebnisse entschied die Gruppe, dass der resultierende Bildsch\"arfungseffekt nicht effektiv genug war, und entschied sich daher, Canny Edge Detection aufzugeben.\\

% MOG2 und KNN
% -> Motivation, Theorie, Codebeschreibung, Resultate

% Frontend: Primer; Paar Buttons eingebaut; Backend mit Funktionen ausgestattet

% Probleme: Coco Dataset,  HED, Django

% Fazit: Limitierungen
% Ausblick: Verbesserungsvorschläge

\section{Inspiration: Langzeitbelichtung} %Erstmal Hendriks Sektion
Das in den Er\"offnungsfolien gezeigte Bildmaterial erinnerte uns in Teilen doch recht stark an eine klassische Langzeitbelichtung, wie man sie aus der Analogfotografie oder der Fotographie mit DSLRs oder DSLMs kennt. Daher stellten wir uns die Frage, wie man dieses Konzept digital nachtr\"aglich unter Zuhilfenahme eines Videos anstelle eines Fotos reproduzieren kann. \\
Der Ansatz, den wir hierbei Verfolgt haben ist relativ trivial. \"Ahnlich wie klassiche Filter den Inhaltswert eines Pixels anhand einer ggf. faktorisierten Durchschnittsberechnung mit den umliegenden Pixeln berechnet tun wir ebendieses - jedoch mit den Pixeln gleicher Koordinaten auf anderen Videoframes. 

\section{Edge Detection und Background Subtraction}

\end{document}
